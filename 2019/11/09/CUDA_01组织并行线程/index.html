<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
  <link rel="mask-icon" href="/images/safari-pinned-tab.svg" color="#222">
  <link rel="alternate" href="/atom.xml" title="Odyssey" type="application/atom+xml">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '7.5.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: true,
    mediumzoom: false,
    lazyload: false,
    pangu: true,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="CUDA编程中最重要的一环就是如何让数据并行计算，要想实现较为高效的并行计算就需要在CUDA编程时手动为每个数据分配线程，这就涉及到如何在不同的grid 和 block 中计算出合适线程的id号。">
<meta name="keywords" content="CUDA,CPP">
<meta property="og:type" content="article">
<meta property="og:title" content="CUDA_01组织并行线程">
<meta property="og:url" content="http:&#x2F;&#x2F;yoursite.com&#x2F;2019&#x2F;11&#x2F;09&#x2F;CUDA_01%E7%BB%84%E7%BB%87%E5%B9%B6%E8%A1%8C%E7%BA%BF%E7%A8%8B&#x2F;index.html">
<meta property="og:site_name" content="Odyssey">
<meta property="og:description" content="CUDA编程中最重要的一环就是如何让数据并行计算，要想实现较为高效的并行计算就需要在CUDA编程时手动为每个数据分配线程，这就涉及到如何在不同的grid 和 block 中计算出合适线程的id号。">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https:&#x2F;&#x2F;qipccc-alipic.oss-cn-shanghai.aliyuncs.com&#x2F;images&#x2F;b8b1bdfda485204b59c940daf0f2fc7.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;qipccc-alipic.oss-cn-shanghai.aliyuncs.com&#x2F;images&#x2F;20191108160350.png">
<meta property="og:image" content="https:&#x2F;&#x2F;qipccc-alipic.oss-cn-shanghai.aliyuncs.com&#x2F;images&#x2F;20191108164506.png">
<meta property="og:image" content="https:&#x2F;&#x2F;qipccc-alipic.oss-cn-shanghai.aliyuncs.com&#x2F;images&#x2F;20191108170505.png">
<meta property="og:image" content="https:&#x2F;&#x2F;qipccc-alipic.oss-cn-shanghai.aliyuncs.com&#x2F;images&#x2F;451431f889b05d3ae630d32f175a126.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;qipccc-alipic.oss-cn-shanghai.aliyuncs.com&#x2F;images&#x2F;a8de254c0be85b7d778bef29d5b33ca.jpg">
<meta property="og:image" content="https:&#x2F;&#x2F;qipccc-alipic.oss-cn-shanghai.aliyuncs.com&#x2F;images&#x2F;20191108232742.png">
<meta property="og:image" content="https:&#x2F;&#x2F;qipccc-alipic.oss-cn-shanghai.aliyuncs.com&#x2F;images&#x2F;20191109132806.png">
<meta property="og:updated_time" content="2019-11-13T01:45:26.181Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https:&#x2F;&#x2F;qipccc-alipic.oss-cn-shanghai.aliyuncs.com&#x2F;images&#x2F;b8b1bdfda485204b59c940daf0f2fc7.jpg">

<link rel="canonical" href="http://yoursite.com/2019/11/09/CUDA_01%E7%BB%84%E7%BB%87%E5%B9%B6%E8%A1%8C%E7%BA%BF%E7%A8%8B/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>CUDA_01组织并行线程 | Odyssey</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Odyssey</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">qipccc的博客</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/09/CUDA_01%E7%BB%84%E7%BB%87%E5%B9%B6%E8%A1%8C%E7%BA%BF%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="qipccc">
      <meta itemprop="description" content="风雨兼程">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Odyssey">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          CUDA_01组织并行线程
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2019-11-09 13:33:04" itemprop="dateCreated datePublished" datetime="2019-11-09T13:33:04+08:00">2019-11-09</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2019-11-13 09:45:26" itemprop="dateModified" datetime="2019-11-13T09:45:26+08:00">2019-11-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CUDA/" itemprop="url" rel="index">
                    <span itemprop="name">CUDA</span>
                  </a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>5.8k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>10 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>CUDA编程中最重要的一环就是如何让数据并行计算，要想实现较为高效的并行计算就需要在CUDA编程时手动为每个数据分配线程，这就涉及到如何在不同的grid 和 block 中计算出合适线程的id号。</p>
<a id="more"></a>
<h2 id="CUDA组织并行线程"><a href="#CUDA组织并行线程" class="headerlink" title="CUDA组织并行线程"></a>CUDA组织并行线程</h2><p><a href="https://face2ai.com/cuda-f-2-3-%e7%bb%84%e7%bb%87%e5%b9%b6%e8%a1%8c%e7%ba%bf%e7%a8%8b/" target="_blank" rel="noopener">文章参考</a></p>
<h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>CUDA编程中最重要的一环就是如何让数据并行计算，要想实现较为高效的并行计算就需要在CUDA编程时手动为每个数据分配线程，这就涉及到如何在不同的grid 和 block 中计算出合适线程的id号。</p>
<p>回顾GPU中一个 kernel 的大致框架：</p>
<p><img src="https://qipccc-alipic.oss-cn-shanghai.aliyuncs.com/images/b8b1bdfda485204b59c940daf0f2fc7.jpg"/></p>
<p>所在一般在编程时需要事先声明grid, block, thread的大小：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">dim3 <span class="title">block</span><span class="params">(<span class="number">4</span>,<span class="number">2</span>)</span></span>;  <span class="comment">// 声明一个 block 其中包含 4 行 2 列 = 8 个线程</span></span><br><span class="line"><span class="function">dim3 <span class="title">grid</span><span class="params">(<span class="number">2</span>,<span class="number">3</span>)</span></span>;  <span class="comment">// 声明一个 grid 其中包含 2 行 3 列 = 6 个block</span></span><br><span class="line"><span class="comment">// 所以总共可分配的线程数为： 8 * 6 = 48 个</span></span><br></pre></td></tr></table></figure>
<p>所以在得到一个block中一个线程的索引号（threadIdx）后，需要还需要根据 gridDim. gridIdx, blockDim, blockIdx 计算获得其全局的索引号。详细: <a href="https://blog.csdn.net/hujingshuang/article/details/53097222#commentBox" target="_blank" rel="noopener">grid、block、thread的关系及thread索引的计算</a></p>
<p>这边以简单的二维block为例介绍：</p>
<p><img src="https://qipccc-alipic.oss-cn-shanghai.aliyuncs.com/images/20191108160350.png"/></p>
<p>计算方式就如图中所示。</p>
<p>因为CUDA 每一个线程执行相同的代码，就是异构计算中的多线程单指令， 如果每个不同的线程执行同样的代码，又处理同一组数据，CUDA常用的做法是让不同的线程对应不同的数据，也就是用线程的全局全局标号对应不同组的数据。因为无论时设备还是主机内存都是线性存在的，比如二维矩阵 $(8 \times 6)$， 存储在内存中可能就是如下结构：</p>
<p><img src="https://qipccc-alipic.oss-cn-shanghai.aliyuncs.com/images/20191108164506.png"/></p>
<p>我们要做的管理就是：</p>
<ul>
<li><p>矩阵和块索引（计算线程的全局索引）；</p>
</li>
<li><p>计算矩阵中给定点的坐标 (ix, iy);</p>
</li>
<li><p>(ix, iy) 对应的线性内存的位置；</p>
</li>
</ul>
<p>线性位置的计算方式：</p>
<script type="math/tex; mode=display">idx = ix + iy \times nx</script><p>这样的分配方式就将数组矩阵中 (ix, iy) 位置处的数据分配到线程标号为 ix,iy 处去计算。</p>
<h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><p>随机生成一个 6 行 8列的数组，总共有 48 个数字，如下：</p>
<p><img src="https://qipccc-alipic.oss-cn-shanghai.aliyuncs.com/images/20191108170505.png"/></p>
<p>实际内存是一维线性的，如下：</p>
<script type="math/tex; mode=display">[29.6 , ... , 22.16 , 26.49 , ... , 23.45 , 30.92 , ... , ...]</script><p>block 和 grid 的大小为：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">dim3 <span class="title">blcok</span><span class="params">(<span class="number">4</span>,<span class="number">2</span>)</span></span>;</span><br><span class="line"><span class="function">dim3 <span class="title">grid</span><span class="params">(<span class="number">2</span>,<span class="number">3</span>)</span></span>;</span><br></pre></td></tr></table></figure>
<p>这里创建了一个二维block和 二维线程，即使用 2 x 3 个block ，每个 block中再开辟 4x 2 个线程， 则 2 x 3 x 4 x 2 = 48，然后将这48个数字分配进去，每个数字一个线程,就相当于每个线程进行一个数字的操作，进行的计算的并行化。</p>
<p>有如下形式：</p>
<p><img src="https://qipccc-alipic.oss-cn-shanghai.aliyuncs.com/images/451431f889b05d3ae630d32f175a126.jpg"/></p>
<p>按照下面的方式打印索引：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">printThreadIndex</span><span class="params">(<span class="keyword">float</span> *A, <span class="keyword">const</span> <span class="keyword">int</span> nx, <span class="keyword">const</span> <span class="keyword">int</span> ny)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">int</span> ix = threadIdx.x + blockIdx.x*blockDim.x;  </span><br><span class="line">	<span class="keyword">int</span> iy = threadIdx.y + blockIdx.y*blockDim.y;</span><br><span class="line">	<span class="keyword">unsigned</span> <span class="keyword">int</span> idx = iy * nx + ix; </span><br><span class="line"><span class="comment">//nx = 8, ny= 6 在进一步计算全局线程标号，是为了将这48个数据分别匹配到不同的线程中去</span></span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">"thread_id(%d,%d) block_id(%d,%d) coordinate(%d,%d)"</span></span><br><span class="line">		<span class="string">"global index %2d ival %2d\n"</span>, threadIdx.x, threadIdx.y,</span><br><span class="line">		blockIdx.x, blockIdx.y, ix, iy, idx, A[idx]);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//dim3 blcok(4,2);</span></span><br><span class="line"><span class="comment">//dim3 grid(2,3);</span></span><br><span class="line"><span class="comment">//int nx = 8;</span></span><br><span class="line"><span class="comment">//int ny = 6;</span></span><br><span class="line">printThreadIndex &lt;&lt; &lt;grid, block &gt;&gt; &gt; (A_dev, nx, ny);</span><br></pre></td></tr></table></figure>
<p>对应的计算示意图如下：</p>
<p><img src="https://qipccc-alipic.oss-cn-shanghai.aliyuncs.com/images/a8de254c0be85b7d778bef29d5b33ca.jpg"/></p>
<p>程序打印输出结果如下：</p>
<p><img src="https://qipccc-alipic.oss-cn-shanghai.aliyuncs.com/images/20191108232742.png"/></p>
<p>设置不同的block或者 grid大小，计算的性能也会不一样的，如下：</p>
<p><img src="https://qipccc-alipic.oss-cn-shanghai.aliyuncs.com/images/20191109132806.png"/></p>
<p>可以看到在GPU上计算明显比CPU上计算快很多。</p>
<h3 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h3><p>时间计算的比较：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"cuda_runtime.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"device_launch_parameters.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"freshman.h"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">sumMatrix2D_CPU</span><span class="params">(<span class="keyword">float</span> * MatA, <span class="keyword">float</span> * MatB, <span class="keyword">float</span> * MatC, <span class="keyword">int</span> nx, <span class="keyword">int</span> ny)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">float</span> * a = MatA;</span><br><span class="line">	<span class="keyword">float</span> * b = MatB;</span><br><span class="line">	<span class="keyword">float</span> * c = MatC;</span><br><span class="line">	<span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; ny; j++)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; nx; i++)</span><br><span class="line">		&#123;</span><br><span class="line">			c[i] = a[i] + b[i];</span><br><span class="line">		&#125;</span><br><span class="line">		c += nx;</span><br><span class="line">		b += nx;</span><br><span class="line">		a += nx;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line">__<span class="function">global__ <span class="keyword">void</span> <span class="title">sumMatrix</span><span class="params">(<span class="keyword">float</span> * MatA, <span class="keyword">float</span> * MatB, <span class="keyword">float</span> * MatC, <span class="keyword">int</span> nx, <span class="keyword">int</span> ny)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="keyword">int</span> ix = threadIdx.x + blockDim.x*blockIdx.x;</span><br><span class="line">	<span class="keyword">int</span> iy = threadIdx.y + blockDim.y*blockIdx.y;</span><br><span class="line">	<span class="keyword">int</span> idx = ix + iy * ny;</span><br><span class="line">	<span class="keyword">if</span> (ix &lt; nx &amp;&amp; iy &lt; ny)</span><br><span class="line">	&#123;</span><br><span class="line">		MatC[idx] = MatA[idx] + MatB[idx];</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>** argv)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">"strating...\n"</span>);</span><br><span class="line">	initDevice(<span class="number">0</span>);</span><br><span class="line">	<span class="keyword">int</span> nx = <span class="number">1</span> &lt;&lt; <span class="number">12</span>;  <span class="comment">//2**12 = 4096</span></span><br><span class="line">	<span class="keyword">int</span> ny = <span class="number">1</span> &lt;&lt; <span class="number">12</span>;  <span class="comment">//2**12 = 4096</span></span><br><span class="line">	<span class="keyword">int</span> nxy = nx * ny;  <span class="comment">// 4096 * 4096</span></span><br><span class="line">	<span class="keyword">int</span> nBytes = nxy * <span class="keyword">sizeof</span>(<span class="keyword">float</span>);  <span class="comment">// nxy 共占用多少个字节</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">//Malloc</span></span><br><span class="line">	<span class="keyword">float</span>* A_host = (<span class="keyword">float</span>*)<span class="built_in">malloc</span>(nBytes);  <span class="comment">// 分配指针空间</span></span><br><span class="line">	<span class="keyword">float</span>* B_host = (<span class="keyword">float</span>*)<span class="built_in">malloc</span>(nBytes);</span><br><span class="line">	<span class="keyword">float</span>* C_host = (<span class="keyword">float</span>*)<span class="built_in">malloc</span>(nBytes);</span><br><span class="line">	<span class="keyword">float</span>* C_from_gpu = (<span class="keyword">float</span>*)<span class="built_in">malloc</span>(nBytes);</span><br><span class="line">	initialData(A_host, nxy);</span><br><span class="line">	initialData(B_host, nxy);</span><br><span class="line"></span><br><span class="line">	<span class="comment">//cudaMalloc</span></span><br><span class="line">	<span class="keyword">float</span> *A_dev = <span class="literal">NULL</span>;</span><br><span class="line">	<span class="keyword">float</span> *B_dev = <span class="literal">NULL</span>;</span><br><span class="line">	<span class="keyword">float</span> *C_dev = <span class="literal">NULL</span>;</span><br><span class="line">	CHECK(cudaMalloc((<span class="keyword">void</span>**)&amp;A_dev, nBytes));</span><br><span class="line">	CHECK(cudaMalloc((<span class="keyword">void</span>**)&amp;B_dev, nBytes));</span><br><span class="line">	CHECK(cudaMalloc((<span class="keyword">void</span>**)&amp;C_dev, nBytes));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	CHECK(cudaMemcpy(A_dev, A_host, nBytes, cudaMemcpyHostToDevice));</span><br><span class="line">	CHECK(cudaMemcpy(B_dev, B_host, nBytes, cudaMemcpyHostToDevice));</span><br><span class="line"></span><br><span class="line">	<span class="keyword">int</span> dimx = <span class="number">32</span>;</span><br><span class="line">	<span class="keyword">int</span> dimy = <span class="number">32</span>;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// cpu compute</span></span><br><span class="line">	cudaMemcpy(C_from_gpu, C_dev, nBytes, cudaMemcpyDeviceToHost);</span><br><span class="line">	<span class="keyword">double</span> iStart = cpuSecond();</span><br><span class="line">	sumMatrix2D_CPU(A_host, B_host, C_host, nx, ny);</span><br><span class="line">	<span class="keyword">double</span> iElaps = cpuSecond() - iStart;</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">"CPU Execution Time elapsed %f sec\n"</span>, iElaps);</span><br><span class="line"></span><br><span class="line">	<span class="comment">//==================================== 2d block and 2d grid ================================</span></span><br><span class="line">	<span class="function">dim3 <span class="title">block_0</span><span class="params">(dimx, dimy)</span></span>; <span class="comment">// blockDim.x = 32， blockDim.y = 32, threadIdx.x(y) in [0,31]</span></span><br><span class="line">	<span class="comment">// (nx - 1)/ block_0.x + 1 相当于 int(nx/block_0.x)</span></span><br><span class="line">	<span class="function">dim3 <span class="title">grid_0</span><span class="params">((nx - <span class="number">1</span>) / block_0.x + <span class="number">1</span>, (ny - <span class="number">1</span>) / block_0.y + <span class="number">1</span>)</span></span>; <span class="comment">//128， 128，  gridDim.x(y) = 128, blockIdx.x(y) in [0,128]</span></span><br><span class="line">	iStart = cpuSecond();</span><br><span class="line">	sumMatrix &lt;&lt; &lt;grid_0, block_0 &gt;&gt; &gt; (A_dev, B_dev, C_dev, nx, ny);</span><br><span class="line">	CHECK(cudaDeviceSynchronize());</span><br><span class="line">	iElaps = cpuSecond() - iStart;</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">"GPU Execution configuration grid and block shape: &lt;&lt;&lt;(%d,%d),(%d,%d)&gt;&gt;&gt; Time elapsed %f sec\n"</span>,</span><br><span class="line">		grid_0.x, grid_0.y, block_0.x, block_0.y, iElaps);</span><br><span class="line">	CHECK(cudaMemcpy(C_from_gpu, C_dev, nBytes, cudaMemcpyDeviceToHost));</span><br><span class="line">	checkResult(C_host, C_from_gpu, nxy);</span><br><span class="line">	<span class="comment">//============================================================================================</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">//=====================================1d block and 1d grid ==================================</span></span><br><span class="line">	dimx = <span class="number">32</span>;</span><br><span class="line">	<span class="function">dim3 <span class="title">block_1</span><span class="params">(dimx)</span></span>;  <span class="comment">// 32</span></span><br><span class="line">	<span class="function">dim3 <span class="title">grid_1</span><span class="params">((nxy - <span class="number">1</span>) / block_1.x + <span class="number">1</span>)</span></span>;  <span class="comment">// (4096 * 4096 -1)/ 32 + 1 = 524288</span></span><br><span class="line">	iStart = cpuSecond();</span><br><span class="line">	sumMatrix &lt;&lt; &lt;grid_1, block_1 &gt;&gt; &gt; (A_dev, B_dev, C_dev, nx*ny, <span class="number">1</span>);</span><br><span class="line">	CHECK(cudaDeviceSynchronize());</span><br><span class="line">	iElaps = cpuSecond() - iStart;</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">"GPU Execution configuration grid and block shape: &lt;&lt;&lt;(%d,%d),(%d,%d)&gt;&gt;&gt; Time elapsed %f sec\n"</span>,</span><br><span class="line">		grid_1.x, grid_1.y, block_1.x, block_1.y, iElaps);</span><br><span class="line">	CHECK(cudaMemcpy(C_from_gpu, C_dev, nBytes, cudaMemcpyDeviceToHost));</span><br><span class="line">	checkResult(C_host, C_from_gpu, nxy);</span><br><span class="line">	<span class="comment">//============================================================================================</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">//===================================== 2d block and 1d grid =================================</span></span><br><span class="line">	dimx = <span class="number">32</span>;</span><br><span class="line">	<span class="function">dim3 <span class="title">block_2</span><span class="params">(dimx)</span></span>; <span class="comment">// 32</span></span><br><span class="line">	<span class="function">dim3 <span class="title">grid_2</span><span class="params">((nx - <span class="number">1</span>) / block_2.x + <span class="number">1</span>, ny)</span></span>;  <span class="comment">// 128, 4096</span></span><br><span class="line">	iStart = cpuSecond();</span><br><span class="line">	sumMatrix &lt;&lt; &lt;grid_2, block_2 &gt;&gt; &gt; (A_dev, B_dev, C_dev, nx, ny);</span><br><span class="line">	CHECK(cudaDeviceSynchronize());</span><br><span class="line">	iElaps = cpuSecond() - iStart;</span><br><span class="line">	<span class="built_in">printf</span>(<span class="string">"GPU Execution configuration grid and block shape: &lt;&lt;&lt;(%d,%d),(%d,%d)&gt;&gt;&gt; Time elapsed %f sec\n"</span>,</span><br><span class="line">		grid_2.x, grid_2.y, block_2.x, block_2.y, iElaps);</span><br><span class="line">	CHECK(cudaMemcpy(C_from_gpu, C_dev, nBytes, cudaMemcpyDeviceToHost));</span><br><span class="line">	checkResult(C_host, C_from_gpu, nxy);</span><br><span class="line">	<span class="comment">//=============================================================================================</span></span><br><span class="line">	cudaFree(A_dev);</span><br><span class="line">	cudaFree(B_dev);</span><br><span class="line">	cudaFree(C_dev);</span><br><span class="line">	<span class="built_in">free</span>(A_host);</span><br><span class="line">	<span class="built_in">free</span>(B_host);</span><br><span class="line">	<span class="built_in">free</span>(C_host);</span><br><span class="line">	<span class="built_in">free</span>(C_from_gpu);</span><br><span class="line">	cudaDeviceReset();</span><br><span class="line">	<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/CUDA/" rel="tag"># CUDA</a>
              <a href="/tags/CPP/" rel="tag"># CPP</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
                <a href="/2019/11/06/20191106%E8%AE%B0%E5%BD%95/" rel="next" title="20191106记录">
                  <i class="fa fa-chevron-left"></i> 20191106记录
                </a>
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
                <a href="/2019/11/09/20191109%E8%AE%B0%E5%BD%95/" rel="prev" title="20191109记录">
                  20191109记录 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    
  <div class="comments" id="comments">
    <div id="lv-container" data-id="city" data-uid="MTAyMC80NzM3My8yMzg3Mw=="></div>
  </div>
  

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#CUDA组织并行线程"><span class="nav-text">CUDA组织并行线程</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#概念"><span class="nav-text">概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#例子"><span class="nav-text">例子</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#附录"><span class="nav-text">附录</span></a></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="site-author-image" itemprop="image" alt="qipccc"
    src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">qipccc</p>
  <div class="site-description" itemprop="description">风雨兼程</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">16</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="feed-link motion-element">
    <a href="/atom.xml" rel="alternate">
      <i class="fa fa-rss"></i>RSS
    </a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">qipccc</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="站点总字数">108k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">3:01</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>












        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/pangu@4/dist/browser/pangu.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/muse.js"></script>
<script src="/js/next-boot.js"></script>



  




  <script src="/js/local-search.js"></script>













  

  
      
<script type="text/x-mathjax-config">
    MathJax.Ajax.config.path['mhchem'] = '//cdn.jsdelivr.net/npm/mathjax-mhchem@3';

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        extensions: ['[mhchem]/mhchem.js'],
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  

<script>
  window.livereOptions = {
    refer: location.pathname.replace(CONFIG.root, '').replace('index.html', '')
  };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
